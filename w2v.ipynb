{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Emotion_classify_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "#wva = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)    \n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "data[\"Comment\"] = data['Comment'].apply(preprocess) \n",
    "\n",
    "\n",
    "data.Comment\n",
    "\n",
    "corpus = [data[\"Comment\"][i] for i in range(0,len(data))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_s = 300\n",
    "\n",
    "model=Word2Vec(sentences = corpus ,epochs =1000  , window=5, vector_size=vector_s, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 0.23737168312072754),\n",
       " ('distract', 0.1942511796951294),\n",
       " ('easy', 0.1718028485774994),\n",
       " ('dead', 0.1657799482345581),\n",
       " ('carry', 0.16488607227802277),\n",
       " ('today', 0.16416817903518677),\n",
       " ('chest', 0.16090591251850128),\n",
       " ('awesome', 0.15755659341812134),\n",
       " ('aspect', 0.15385007858276367),\n",
       " ('weak', 0.1493191123008728)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def avg_word2vec(doc):  \n",
    "        return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC1\\Desktop\\NLP\\RNNv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\PC1\\Desktop\\NLP\\RNNv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "X_avg = []\n",
    "for sentence in data[\"Comment\"]:\n",
    "    X_avg.append(avg_word2vec(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_4288\\1501679086.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df= pd.concat([pd.DataFrame(X_avg[i].reshape(1,-1)), df] , ignore_index=True  )\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "for i in range(0,len(X_avg)):\n",
    "    df= pd.concat([pd.DataFrame(X_avg[i].reshape(1,-1)), df] , ignore_index=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5937 entries, 0 to 5936\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float32(300)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\AppData\\Local\\Temp\\ipykernel_4288\\1359161491.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  target = target.replace({\"fear\" : 0 , \"anger\" :1 , \"joy\":2})\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "target= data[[\"Emotion\"]]\n",
    "\n",
    "target = target.replace({\"fear\" : 0 , \"anger\" :1 , \"joy\":2})\n",
    "\n",
    "target = target.astype(int)\n",
    "\n",
    "target = keras.utils.to_categorical(target.Emotion, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test/train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(df,target,test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    for i in range(hp.Int(\"num_layers\", 1, vector_s)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                \n",
    "                units=hp.Int(f\"units_{i}\", min_value=10, max_value=500, step=5),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\",\"leaky_relu\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(keras.layers.Dropout(rate=0.25))\n",
    "    model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\"categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"categorical_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"classifier\",\n",
    "    project_name=\"WV\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 26s]\n",
      "categorical_accuracy: 0.3284901976585388\n",
      "\n",
      "Best categorical_accuracy So Far: 0.3407033085823059\n",
      "Total elapsed time: 00h 18m 16s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train ,epochs=100,validation_data=(X_test,y_test) , callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,170</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,010</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,765</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">475</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,850</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,428</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m3,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m)            │        \u001b[38;5;34m51,170\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m310\u001b[0m)            │        \u001b[38;5;34m53,010\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │        \u001b[38;5;34m12,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)            │         \u001b[38;5;34m6,765\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m475\u001b[0m)            │        \u001b[38;5;34m78,850\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,428\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,963</span> (808.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,963\u001b[0m (808.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,963</span> (808.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m206,963\u001b[0m (808.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Best model\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 109ms/step - categorical_accuracy: 0.3210 - loss: 1.0988 - val_categorical_accuracy: 0.3547 - val_loss: 1.0982\n",
      "Epoch 2/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - categorical_accuracy: 0.3418 - loss: 1.0988 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 3/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 90ms/step - categorical_accuracy: 0.3409 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 4/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - categorical_accuracy: 0.3453 - loss: 1.0986 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 5/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - categorical_accuracy: 0.3482 - loss: 1.0982 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 6/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - categorical_accuracy: 0.3348 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 7/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3566 - loss: 1.0980 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 8/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - categorical_accuracy: 0.3323 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0986\n",
      "Epoch 9/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - categorical_accuracy: 0.3446 - loss: 1.0984 - val_categorical_accuracy: 0.3253 - val_loss: 1.0988\n",
      "Epoch 10/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - categorical_accuracy: 0.3492 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0986\n",
      "Epoch 11/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - categorical_accuracy: 0.3433 - loss: 1.0982 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 12/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - categorical_accuracy: 0.3270 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0992\n",
      "Epoch 13/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - categorical_accuracy: 0.3501 - loss: 1.0982 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 14/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - categorical_accuracy: 0.3548 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0984\n",
      "Epoch 15/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - categorical_accuracy: 0.3606 - loss: 1.0975 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 16/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - categorical_accuracy: 0.3333 - loss: 1.0990 - val_categorical_accuracy: 0.3253 - val_loss: 1.0988\n",
      "Epoch 17/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - categorical_accuracy: 0.3318 - loss: 1.0987 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 18/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - categorical_accuracy: 0.3241 - loss: 1.0992 - val_categorical_accuracy: 0.3253 - val_loss: 1.0994\n",
      "Epoch 19/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3316 - loss: 1.0992 - val_categorical_accuracy: 0.3253 - val_loss: 1.0991\n",
      "Epoch 20/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - categorical_accuracy: 0.3451 - loss: 1.0984 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 21/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 102ms/step - categorical_accuracy: 0.3583 - loss: 1.0977 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 22/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - categorical_accuracy: 0.3288 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 23/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - categorical_accuracy: 0.3410 - loss: 1.0987 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 24/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - categorical_accuracy: 0.3439 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 25/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 109ms/step - categorical_accuracy: 0.3456 - loss: 1.0981 - val_categorical_accuracy: 0.3253 - val_loss: 1.0986\n",
      "Epoch 26/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3283 - loss: 1.0988 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 27/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - categorical_accuracy: 0.3482 - loss: 1.0984 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 28/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - categorical_accuracy: 0.3536 - loss: 1.0982 - val_categorical_accuracy: 0.3253 - val_loss: 1.0984\n",
      "Epoch 29/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - categorical_accuracy: 0.3474 - loss: 1.0979 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 30/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - categorical_accuracy: 0.3401 - loss: 1.0986 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 31/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - categorical_accuracy: 0.3401 - loss: 1.0986 - val_categorical_accuracy: 0.3253 - val_loss: 1.0991\n",
      "Epoch 32/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - categorical_accuracy: 0.3468 - loss: 1.0984 - val_categorical_accuracy: 0.3253 - val_loss: 1.0986\n",
      "Epoch 33/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - categorical_accuracy: 0.3541 - loss: 1.0979 - val_categorical_accuracy: 0.3253 - val_loss: 1.0985\n",
      "Epoch 34/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - categorical_accuracy: 0.3392 - loss: 1.0989 - val_categorical_accuracy: 0.3253 - val_loss: 1.0988\n",
      "Epoch 35/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - categorical_accuracy: 0.3397 - loss: 1.0990 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 36/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - categorical_accuracy: 0.3377 - loss: 1.0991 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 37/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - categorical_accuracy: 0.3385 - loss: 1.0986 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 38/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3484 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0986\n",
      "Epoch 39/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - categorical_accuracy: 0.3576 - loss: 1.0977 - val_categorical_accuracy: 0.3253 - val_loss: 1.0984\n",
      "Epoch 40/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - categorical_accuracy: 0.3454 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0991\n",
      "Epoch 41/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 108ms/step - categorical_accuracy: 0.3379 - loss: 1.0987 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 42/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - categorical_accuracy: 0.3403 - loss: 1.0985 - val_categorical_accuracy: 0.3253 - val_loss: 1.0991\n",
      "Epoch 43/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3401 - loss: 1.0987 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 44/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - categorical_accuracy: 0.3283 - loss: 1.0993 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 45/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - categorical_accuracy: 0.3476 - loss: 1.0983 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 46/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - categorical_accuracy: 0.3424 - loss: 1.0985 - val_categorical_accuracy: 0.3253 - val_loss: 1.0989\n",
      "Epoch 47/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - categorical_accuracy: 0.3412 - loss: 1.0988 - val_categorical_accuracy: 0.3253 - val_loss: 1.0988\n",
      "Epoch 48/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - categorical_accuracy: 0.3445 - loss: 1.0985 - val_categorical_accuracy: 0.3253 - val_loss: 1.0987\n",
      "Epoch 49/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - categorical_accuracy: 0.3406 - loss: 1.0984 - val_categorical_accuracy: 0.3253 - val_loss: 1.0990\n",
      "Epoch 50/50\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - categorical_accuracy: 0.3491 - loss: 1.0979 - val_categorical_accuracy: 0.3253 - val_loss: 1.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24fcf35e3c0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "\n",
    "model_clf = build_model(best_hps[0])\n",
    "\n",
    "model_clf.fit(x=X_train, y=y_train, validation_split=0.2 ,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32419068, 0.34285554, 0.33295378],\n",
       "       [0.32419068, 0.34285554, 0.33295378],\n",
       "       [0.32419068, 0.34285554, 0.33295378],\n",
       "       ...,\n",
       "       [0.32419068, 0.34285554, 0.33295378],\n",
       "       [0.32419068, 0.34285554, 0.33295378],\n",
       "       [0.32419068, 0.34285554, 0.33295378]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ar = [np.argmax(prediction) for prediction in pred]\n",
    "y_test_ar = [np.argmax(y) for y in y_test]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
